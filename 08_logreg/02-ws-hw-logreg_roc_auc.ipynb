{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Это просто чтобы на проекторе всё было красиво.\n",
    "# Не обращайте внимания\n",
    "\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"\"\"\n",
    "<style>\n",
    "\n",
    "div.cell { /* Tunes the space between cells */\n",
    "margin-top:1em;\n",
    "margin-bottom:1em;\n",
    "}\n",
    "\n",
    "div.text_cell_render h1 { /* Main titles bigger, centered */\n",
    "font-size: 1.8em;\n",
    "line-height:1.0em;\n",
    "text-align:center;\n",
    "}\n",
    "\n",
    "div.text_cell_render h2 { /*  Parts names nearer from text */\n",
    "margin-bottom: -0.4em;\n",
    "}\n",
    "\n",
    "\n",
    "div.text_cell_render { /* Customize text cells */\n",
    "font-family: 'Times New Roman';\n",
    "font-size:1.4em;\n",
    "line-height:1.3em;\n",
    "padding-left:2em;\n",
    "padding-right:2em;\n",
    "}\n",
    "</style>\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn\n",
    "%matplotlib inline\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Где логистическая регрессия хороша и где не очень"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Анализ отзывов IMDB к фильмам"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем решать задачу бинарной классификации отзывов IMDB к фильмам. Имеется обучающая выборка с размеченными отзывами, по 12500 отзывов известно, что они хорошие, еще про 12500 – что они плохие. Здесь уже не так просто сразу приступить к машинному обучению, потому что готовой матрицы $X$ нет  – ее надо приготовить. Будем использовать самый простой подход – мешок слов (\"Bag of words\"). При таком подходе признаками отзыва будут индикаторы наличия в нем каждого слова из всего корпуса, где корпус – это множество всех отзывов. Идея иллюстрируется картинкой\n",
    "\n",
    "<img src=\"https://hsto.org/files/a0a/bb1/2e9/a0abb12e9ed94624ade0b9090d26ad66.png\" width=80%>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "# отключим всякие предупреждения Anaconda\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_files\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Загрузим данные [отсюда](http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz) (это прямая ссылка на скачивание, а [вот](http://ai.stanford.edu/~amaas/data/sentiment/) описание набора данных). В обучающей и тестовой выборках по 12500 тысяч хороших и плохих отзывов к фильмам.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# распакуйте архив в папку data \n",
    "reviews_train = load_files(\"../data/aclImdb/train\", categories=['pos', 'neg'])\n",
    "text_train, y_train = reviews_train.data, reviews_train.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of documents in training data: %d\" % len(text_train))\n",
    "print(np.bincount(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_test = load_files(\"../data/aclImdb/test\")\n",
    "text_test, y_test = reviews_test.data, reviews_test.target\n",
    "print(\"Number of documents in test data: %d\" % len(text_test))\n",
    "print(np.bincount(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Пример отзыва и соответствующей метки.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(text_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[1] # плохой отзыв"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_train[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[2] # хороший отзыв"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Простой подсчет слов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Составьте словарь всех слов с помощью CountVectorizer.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Ваш код ###\n",
    "\n",
    "len(cv.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Посмотрим на примеры полученных \"слов\" (лучше их называть токенами). Видим, что многие важные этапы обработки текста мы тут пропустили.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cv.get_feature_names()[:50])\n",
    "print(cv.get_feature_names()[50000:50050])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Закодируйте предложения из текстов обучающей выборки индексами входящих слов.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = ### Ваш код ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Посмотрим, как преобразование подействовало на одно из предложений.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(text_train[19726])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[19726].nonzero()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[19726].nonzero()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Преобразуйте так же тестовую выборку.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = ### Ваш код ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Обучите логистическую регрессию.** <p> Используйте класс [LogisticRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html). Не забудьте зафиксировать random_state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "### Ваш код ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Выведите доли правильных ответов на обучающей и тестовой выборках.** <p> **Hint:** у класса логрегрессии есть метод на это."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Ваш код ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Теперь то же самое, но со случайным лесом.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Ваш код ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "### В этой ячейке напишите код только для тренировки модели ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Выведите точность предсказания ###"
   ]
  },
  {
   "source": [
    "Видим, что с логистической регрессией мы достигаем большей доли правильных ответов меньшими усилиями"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XOR-проблема\n",
    "Теперь рассмотрим пример, где линейные модели справляются хуже. \n",
    "\n",
    "Линейные методы классификации строят все же очень простую разделяющую поверхность – гиперплоскость. Самый известный игрушечный пример, в котором классы нельзя без ошибок поделить гиперплоскостью (то есть прямой, если это 2D), получил имя \"the XOR problem\".\n",
    "\n",
    "XOR – это \"исключающее ИЛИ\", булева функция со следующей таблицей истинности:\n",
    "\n",
    "<img src='https://hsto.org/files/aa7/c61/7c9/aa7c617c9ce4458d88979b6d44a1e2fa.gif'>\n",
    "\n",
    "XOR дал имя простой задаче бинарной классификации, в которой классы представлены вытянутыми по диагоналям и пересекающимися облаками точек. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# порождаем данные\n",
    "rng = np.random.RandomState(0)\n",
    "X = rng.randn(200, 2)\n",
    "y = np.logical_xor(X[:, 0] > 0, X[:, 1] > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X[:, 0], X[:, 1], s=30, c=y, cmap=plt.cm.Paired);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Очевидно, нельзя провести прямую так, чтобы без ошибок отделить один класс от другого. Поэтому логистическая регрессия плохо справляется с такой задачей. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_boundary(clf, X, y, plot_title):\n",
    "    xx, yy = np.meshgrid(np.linspace(-3, 3, 50),\n",
    "                     np.linspace(-3, 3, 50))\n",
    "    clf.fit(X, y)\n",
    "    # plot the decision function for each datapoint on the grid\n",
    "    Z = clf.predict_proba(np.vstack((xx.ravel(), yy.ravel())).T)[:, 1]\n",
    "    Z = Z.reshape(xx.shape)\n",
    "\n",
    "    image = plt.imshow(Z, interpolation='nearest',\n",
    "                           extent=(xx.min(), xx.max(), yy.min(), yy.max()),\n",
    "                           aspect='auto', origin='lower', cmap=plt.cm.PuOr_r)\n",
    "    contours = plt.contour(xx, yy, Z, levels=[0], linewidths=2,\n",
    "                               linetypes='--')\n",
    "    plt.scatter(X[:, 0], X[:, 1], s=30, c=y, cmap=plt.cm.Paired)\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "    plt.xlabel(r'$x_1$')\n",
    "    plt.ylabel(r'$x_2$')\n",
    "    plt.axis([-3, 3, -3, 3])\n",
    "    plt.colorbar(image)\n",
    "    plt.title(plot_title, fontsize=12);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь, используя функцию, объявленную выше, обучите логистическую регрессию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Ваш код ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А вот если на вход подать полиномиальные признаки, в данном случае до 2 степени, то проблема решается.\n",
    "\n",
    "Теперь, сделайте точно так же, как в прошлой ячейке, но теперь используйте данные, предобработанные до полинома второй степени.\n",
    "\n",
    "**Hint:** Используйте [PolynomialFeatures](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html) и [Pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Ваш код ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь логистическая регрессия все равно строила гиперплоскость, но в 6-мерном пространстве признаков $1, x_1, x_2, x_1^2, x_1x_2$ и $x_2^2$. В проекции на исходное пространство признаков $x_1, x_2$ граница получилась нелинейной. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На практике полиномиальные признаки действительно помогают, но строить их явно – вычислительно неэффективно. Гораздо быстрее работает SVM с ядровым трюком. При таком подходе в пространстве высокой размерности считается только расстояние между объектами (задаваемое функцией-ядром), а явно плодить комбинаторно большое число признаков не приходится. Про это подробно можно почитать в курсе Евгения Соколова – тут (математика уже серьезная)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Метрики качества бинарной классификации\n",
    "\n",
    "Из лекции вы узнали про алгоритмы, которые выдают вероятности принадлежности классу. Но в классификации требуется четко сказать имя класса объекта. Значит, нужно уметь выбирать пороги $T$ для перевода вероятностей в классы. Поэтому необходимы дополнительные подходы для оценки таких алгоритмов, так как классические accuracy, f1 и прочие не принимают во внимание вероятностную природу предсказания.\n",
    "\n",
    "В этой практике мы посмотрим как можно визуализировать precision-recall кривую и ROC_AUC кривую.\n",
    "\n",
    "### Литература\n",
    "\n",
    "- практикика из курса от МФТИ на coursera\n",
    "- [AUC ROC - alexanderdyakonov](https://alexanderdyakonov.wordpress.com/2017/07/28/auc-roc-%D0%BF%D0%BB%D0%BE%D1%89%D0%B0%D0%B4%D1%8C-%D0%BF%D0%BE%D0%B4-%D0%BA%D1%80%D0%B8%D0%B2%D0%BE%D0%B9-%D0%BE%D1%88%D0%B8%D0%B1%D0%BE%D0%BA/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим несколько вариантов векторов предсказаний вероятностей принадлежности классам. Каждый из вариантов будет показывать особенности классификаторов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# рисует один scatter plot\n",
    "def scatter(actual, predicted, T):\n",
    "    plt.scatter(actual, predicted)\n",
    "    plt.xlabel(\"Labels\")\n",
    "    plt.ylabel(\"Predicted probabilities\")\n",
    "    plt.plot([-0.2, 1.2], [T, T])\n",
    "    plt.axis([-0.1, 1.1, -0.1, 1.1])\n",
    "    \n",
    "# рисует несколько scatter plot в таблице, имеющей размеры shape\n",
    "def many_scatters(actuals, predicteds, Ts, titles, shape):\n",
    "    plt.figure(figsize=(shape[1]*5, shape[0]*5))\n",
    "    i = 1\n",
    "    for actual, predicted, T, title in zip(actuals, predicteds, Ts, titles):\n",
    "        ax = plt.subplot(shape[0], shape[1], i)\n",
    "        ax.set_title(title)\n",
    "        i += 1\n",
    "        scatter(actual, predicted, T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим:\n",
    "- Идеальный классификатор, который не допускает ошибки\n",
    "- Тпичный классификатор, с незначительными ошибками возле точки разделения\n",
    "- Ужасный классификатор, который всё перепутал"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Идеальный классификатор\n",
    "actual_0 = np.array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  \n",
    "          1.,  1.,  1., 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
    "predicted_0 = np.array([ 0.19015288,  0.23872404,  0.42707312,  0.15308362,  0.2951875 ,\n",
    "            0.23475641,  0.17882447,  0.36320878,  0.33505476,  0.202608  ,\n",
    "            0.82044786,  0.69750253,  0.60272784,  0.9032949 ,  0.86949819,\n",
    "            0.97368264,  0.97289232,  0.75356512,  0.65189193,  0.95237033,\n",
    "            0.91529693,  0.8458463 ])\n",
    "\n",
    "# Типичный классификация\n",
    "actual_1 = np.array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
    "                    0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
    "                    1.,  1.,  1.,  1.])\n",
    "predicted_1 = np.array([ 0.41310733,  0.43739138,  0.22346525,  0.46746017,  0.58251177,\n",
    "            0.38989541,  0.43634826,  0.32329726,  0.01114812,  0.41623557,\n",
    "            0.54875741,  0.48526472,  0.21747683,  0.05069586,  0.16438548,\n",
    "            0.68721238,  0.72062154,  0.90268312,  0.46486043,  0.99656541,\n",
    "            0.59919345,  0.53818659,  0.8037637 ,  0.272277  ,  0.87428626,\n",
    "            0.79721372,  0.62506539,  0.63010277,  0.35276217,  0.56775664])\n",
    "# Ужасный класификатор\n",
    "actual_2 = np.array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,\n",
    "            0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
    "predicted_2 = np.array([ 0.07058193,  0.57877375,  0.42453249,  0.56562439,  0.13372737,\n",
    "            0.18696826,  0.09037209,  0.12609756,  0.14047683,  0.06210359,\n",
    "            0.36812596,  0.22277266,  0.79974381,  0.94843878,  0.4742684 ,\n",
    "            0.80825366,  0.83569563,  0.45621915,  0.79364286,  0.82181152,\n",
    "            0.44531285,  0.65245348,  0.69884206,  0.69455127])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "many_scatters([actual_0, actual_1, actual_2], \n",
    "              [predicted_0, predicted_1, predicted_2], \n",
    "              [0.5, 0.5, 0.5], \n",
    "              [\"Perfect\", \"Typical\", \"Awful algorithm\"], \n",
    "              (1, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вопрос**: Можно ли улучшить _типичный_ алгоритм и если можно то как? (а если нельзя, то почему?)\n",
    "\n",
    "А что на счёт *ужасного* алгоритма, поддаётся ли он улучшению?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ваш ответ: ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь, рассмотрим 2 вида алгоритмов - рискующий и осторожный:\n",
    "\n",
    "Алгоритм может быть осторожным и стремиться сильно не отклонять вероятности от 0.5, а может рисковать - делать предсказания близакими к нулю или единице."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# рискующий идеальный алгоитм\n",
    "actual_0r = np.array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  1.,\n",
    "            1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
    "predicted_0r = np.array([ 0.23563765,  0.16685597,  0.13718058,  0.35905335,  0.18498365,\n",
    "            0.20730027,  0.14833803,  0.18841647,  0.01205882,  0.0101424 ,\n",
    "            0.10170538,  0.94552901,  0.72007506,  0.75186747,  0.85893269,\n",
    "            0.90517219,  0.97667347,  0.86346504,  0.72267683,  0.9130444 ,\n",
    "            0.8319242 ,  0.9578879 ,  0.89448939,  0.76379055])\n",
    "\n",
    "# рискующий хороший алгоритм\n",
    "actual_1r = np.array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,\n",
    "            1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
    "predicted_1r = np.array([ 0.13832748,  0.0814398 ,  0.16136633,  0.11766141,  0.31784942,\n",
    "            0.14886991,  0.22664977,  0.07735617,  0.07071879,  0.92146468,\n",
    "            0.87579938,  0.97561838,  0.75638872,  0.89900957,  0.93760969,\n",
    "            0.92708013,  0.82003675,  0.85833438,  0.67371118,  0.82115125,\n",
    "            0.87560984,  0.77832734,  0.7593189,  0.81615662,  0.11906964,\n",
    "            0.18857729])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "many_scatters([actual_0, actual_1, actual_0r, actual_1r], \n",
    "              [predicted_0, predicted_1, predicted_0r, predicted_1r], \n",
    "              [0.5, 0.5, 0.5, 0.5],\n",
    "              [\"Perfect careful\", \"Typical careful\", \"Perfect risky\", \"Typical risky\"], \n",
    "              (2, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также интервалы могут смещаться. Если алгоритм боится ошибок false positive, то он будет чаще делать предсказания, близкие к нулю. Аналогично, чтобы избежать ошибок false negative, логично чаще предсказывать большие вероятности."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_10 = np.array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
    "                0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
    "                1.,  1.,  1.])\n",
    "predicted_10 = np.array([ 0.29340574, 0.47340035,  0.1580356 ,  0.29996772,  0.24115457,  0.16177793,\n",
    "                         0.35552878,  0.18867804,  0.38141962,  0.20367392,  0.26418924, 0.16289102, \n",
    "                         0.27774892,  0.32013135,  0.13453541, 0.39478755,  0.96625033,  0.47683139,  \n",
    "                         0.51221325,  0.48938235, 0.57092593,  0.21856972,  0.62773859,  0.90454639,  0.19406537,\n",
    "                         0.32063043,  0.4545493 ,  0.57574841,  0.55847795 ])\n",
    "actual_11 = np.array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
    "                0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n",
    "predicted_11 = np.array([ 0.35929566, 0.61562123,  0.71974688,  0.24893298,  0.19056711,  0.89308488,\n",
    "            0.71155538,  0.00903258,  0.51950535,  0.72153302,  0.45936068,  0.20197229,  0.67092724,\n",
    "                         0.81111343,  0.65359427,  0.70044585,  0.61983513,  0.84716577,  0.8512387 ,  \n",
    "                         0.86023125,  0.7659328 ,  0.70362246,  0.70127618,  0.8578749 ,  0.83641841,  \n",
    "                         0.62959491,  0.90445368])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "many_scatters([actual_1, actual_10, actual_11], \n",
    "              [predicted_1, predicted_10, predicted_11], \n",
    "              [0.5, 0.5, 0.5], \n",
    "              [\"Typical\", \"Avoids FP\", \"Avoids FN\"], \n",
    "              (1, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вопрос**: что нужно сделать, чтобы *типичный* алгоритм избегал ошибки первого рода? А второго? А как оптимальнее?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ваш ответ: ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision и recall, accuracy\n",
    "\n",
    "Для начала разберемся с метриками, оценивающие качество уже после бинаризации по порогу T, то есть сравнивающие два бинарных вектора: actual и predicted.\n",
    "\n",
    "Две популярные метрики - precision и recall. Первая показывает, как часто алгоритм предсказывает класс 1 и оказывается правым, а вторая - как много объектов класса 1 алгоритм нашел.\n",
    "\n",
    "Также рассмотрим самую простую и известную метрику - accuracy; она показывает долю правильных ответов.\n",
    "\n",
    "Выясним преимущества и недостатки этих метрик, попробовав их на разных векторах вероятностей.\n",
    "\n",
    "#### Напоминание\n",
    "\n",
    "![](https://i.imgur.com/8xhLDz8.png)\n",
    "\n",
    "$\\LARGE precision = \\frac{TP}{TP+FP}$\n",
    "\n",
    "$\\LARGE recall = \\frac{TP}{TP+FN}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, precision_recall_curve, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "\n",
    "T = 0.5\n",
    "\n",
    "for actual, predicted, descr in zip([actual_0, actual_1, actual_2], \n",
    "                                    [predicted_0 > T, predicted_1 > T, predicted_2 > T],\n",
    "                                    [\"Perfect:\", \"Typical:\", \"Awful:\"]):\n",
    "    res.append([descr, \n",
    "                precision_score(actual, predicted), \n",
    "                recall_score(actual, predicted),\n",
    "                accuracy_score(actual, predicted)])\n",
    "\n",
    "for actual, predicted, descr in zip([actual_1, actual_1r], \n",
    "                                    [predicted_1 > T, predicted_1r > T],\n",
    "                                    [\"Typical careful:\", \"Typical risky:\"]):\n",
    "    res.append([descr, \n",
    "                precision_score(actual, predicted), \n",
    "                recall_score(actual, predicted),\n",
    "                accuracy_score(actual, predicted)])\n",
    "    \n",
    "for actual, predicted, descr in zip([actual_10, actual_11], \n",
    "                                    [predicted_10 > T, predicted_11 > T], \n",
    "                                    [\"Avoids FP:\", \"Avoids FN:\"]):\n",
    "    res.append([descr, \n",
    "                precision_score(actual, predicted), \n",
    "                recall_score(actual, predicted),\n",
    "                accuracy_score(actual, predicted)])\n",
    "    \n",
    "pd.DataFrame(res, columns=['type', 'precision', 'recall', 'accurasy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все три метрики легко различают простые случаи хороших и плохих алгоритмов. Обратим внимание, что метрики имеют область значений `[0, 1]`, и потому их легко интерпретировать.\n",
    "\n",
    "Метрикам не важны величины вероятностей, им важно только то, сколько объектов неправильно зашли за установленную границу (в данном случае `T = 0.5`).\n",
    "\n",
    "Метрика `accuracy` дает одинаковый вес ошибкам `false positive` и `false negative`, зато пара метрик `precision` и `recall` однозначно идентифицирует это различие. Собственно, их для того и используют, чтобы контролировать ошибки `FP` и `FN`.\n",
    "\n",
    "Мы измерили три метрики, фиксировав порог `T = 0.5`, потому что для почти всех картинок он кажется оптимальным. Давайте посмотрим на последней (самой интересной для этих метрик) группе векторов, как меняются `precision` и `recall` при увеличении порога."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precs = []\n",
    "recs = []\n",
    "threshs = []\n",
    "labels = [\"Typical\", \"Avoids FP\", \"Avoids FN\"]\n",
    "f1 = []\n",
    "\n",
    "for actual, predicted in zip([actual_1, actual_10, actual_11], [predicted_1, predicted_10, predicted_11]):\n",
    "    prec, rec, thresh = precision_recall_curve(actual, predicted)\n",
    "    precs.append(prec)\n",
    "    recs.append(rec)\n",
    "    f1.append(np.array([None] + [f1_score(actual, predicted > t) for t in thresh]))\n",
    "    threshs.append(thresh)\n",
    "    \n",
    "plt.figure(figsize=(15, 5))\n",
    "for i in range(3):\n",
    "    ax = plt.subplot(1, 3, i+1)\n",
    "    plt.plot(threshs[i], precs[i][:-1], label=\"precision\")\n",
    "    plt.plot(threshs[i], recs[i][:-1], label=\"recall\")\n",
    "    plt.plot(threshs[i], f1[i][:-1], '--', label=\"f1\")\n",
    "    plt.xlabel(\"threshold\")\n",
    "    ax.set_title(labels[i])\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При увеличении порога мы делаем меньше ошибок `FP` и больше ошибок `FN`, поэтому одна из кривых растет, а вторая - падает. По такому графику можно подобрать оптимальное значение порога, при котором `precision` и `recall` будут приемлемы. Если такого порога не нашлось, нужно обучать другой алгоритм.\n",
    "\n",
    "Оговоримся, что приемлемые значения `precision` и `recall` определяются предметной областью. Например, в задаче определения, болен ли пациент определенной болезнью (0 - здоров, 1 - болен), ошибок `false negative` стараются избегать, требуя `recall` около 0.9. Можно сказать человеку, что он болен, и при дальнейшей диагностике выявить ошибку; гораздо хуже пропустить наличие болезни."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC и AUC\n",
    "\n",
    "[Хорошее объяснение](https://alexanderdyakonov.wordpress.com/2017/07/28/auc-roc-%D0%BF%D0%BB%D0%BE%D1%89%D0%B0%D0%B4%D1%8C-%D0%BF%D0%BE%D0%B4-%D0%BA%D1%80%D0%B8%D0%B2%D0%BE%D0%B9-%D0%BE%D1%88%D0%B8%D0%B1%D0%BE%D0%BA/)\n",
    "\n",
    "При построении ROC-кривой (receiver operating characteristic) происходит варьирование порога бинаризации вектора вероятностей, и вычисляются величины, зависящие от числа ошибок `FP` и `FN`. Эти величины задаются так, чтобы в случае, когда существует порог для идеального разделения классов, ROC-кривая проходила через определенную точку - верхний левый угол квадрата `[0, 1] x [0, 1]`. Кроме того, она всегда проходит через левый нижний и правый верхний углы. Получается наглядная визуализация качества алгоритма. С целью охарактеризовать эту визуализацию численно, ввели понятие AUC - площадь под ROC-кривой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1, 3, 1)\n",
    "aucs = \"\"\n",
    "\n",
    "\n",
    "for actual, predicted, descr in zip([actual_0, actual_1, actual_2], \n",
    "                                    [predicted_0, predicted_1, predicted_2],\n",
    "                                    [\"Perfect\", \"Typical\", \"Awful\"]):\n",
    "    fpr, tpr, thr = roc_curve(actual, predicted)\n",
    "    plt.plot(fpr, tpr, label=descr)\n",
    "    aucs += descr + \":%3f\"%roc_auc_score(actual, predicted) + \" \"\n",
    "    \n",
    "    \n",
    "plt.xlabel(\"false positive rate\")\n",
    "plt.ylabel(\"true positive rate\")\n",
    "plt.legend(loc=4)\n",
    "plt.axis([-0.1, 1.1, -0.1, 1.1])\n",
    "plt.subplot(1, 3, 2)\n",
    "\n",
    "\n",
    "for actual, predicted, descr in zip([actual_0, actual_0r, actual_1, actual_1r], \n",
    "                                    [predicted_0, predicted_0r, predicted_1, predicted_1r],\n",
    "                                    [\"Ideal careful\", \"Ideal Risky\", \"Typical careful\", \"Typical risky\"]):\n",
    "    fpr, tpr, thr = roc_curve(actual, predicted)\n",
    "    aucs += descr + \":%3f\"%roc_auc_score(actual, predicted) + \" \"\n",
    "    plt.plot(fpr, tpr, label=descr)\n",
    "    \n",
    "    \n",
    "plt.xlabel(\"false positive rate\")\n",
    "plt.ylabel(\"true positive rate\")\n",
    "plt.legend(loc=4)\n",
    "plt.axis([-0.1, 1.1, -0.1, 1.1])\n",
    "plt.subplot(1, 3, 3)\n",
    "\n",
    "\n",
    "for actual, predicted, descr in zip([actual_1, actual_10, actual_11], \n",
    "                                    [predicted_1, predicted_10, predicted_11], \n",
    "                                    [\"Typical\", \"Avoids FP\", \"Avoids FN\"]):\n",
    "    fpr, tpr, thr = roc_curve(actual, predicted)\n",
    "    aucs += descr + \":%3f\"%roc_auc_score(actual, predicted) + \" \"\n",
    "    plt.plot(fpr, tpr, label=descr)\n",
    "    \n",
    "    \n",
    "plt.xlabel(\"false positive rate\")\n",
    "plt.ylabel(\"true positive rate\")\n",
    "plt.legend(loc=4)\n",
    "plt.axis([-0.1, 1.1, -0.1, 1.1])\n",
    "print(aucs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чем больше объектов в выборке, тем более гладкой выглядит кривая (хотя на самом деле она все равно ступенчатая).\n",
    "\n",
    "После того, как кривая построена, удобно выбирать порог бинаризации, в котором будет достигнут компромисс между FP или FN. Порог соответствует точке на кривой. Если мы хотим избежать ошибок FP, нужно выбирать точку на левой стороне квадрата (как можно выше), если FN - точку на верхней стороне квадрата (как можно левее). Все промежуточные точки будут соответствовать разным пропорциям FP и FN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log Loss\n",
    "\n",
    "Существуют метрики, которые оценивают вероятности в лоб, без использования какого-то порога. Такие метрики полезны, если необходима степень уверенности алгоритма, а не сам класс.\n",
    "\n",
    "$\\Large log\\_loss(y, y') = - \\frac 1 n \\sum_{i=1}^n (y_i \\cdot \\log (y'_i) + (1-y_i) \\cdot \\log (1-y'_i))$, \n",
    "\n",
    "где $n$ - длина векторов.\n",
    "\n",
    "`Log Loss` можно обобщить на мультилейбл классификацию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "\n",
    "res = []\n",
    "\n",
    "for actual, predicted, descr in zip([actual_0, actual_1, actual_2], \n",
    "                                    [predicted_0, predicted_1, predicted_2],\n",
    "                                    [\"Perfect:\", \"Typical:\", \"Awful:\"]):\n",
    "    res.append([descr, \n",
    "                log_loss(actual, predicted)])\n",
    "\n",
    "for actual, predicted, descr in zip([actual_1, actual_1r], \n",
    "                                    [predicted_1, predicted_1r],\n",
    "                                    [\"Typical careful:\", \"Typical risky:\"]):\n",
    "    res.append([descr, \n",
    "                log_loss(actual, predicted)])\n",
    "    \n",
    "for actual, predicted, descr in zip([actual_10, actual_11], \n",
    "                                    [predicted_10, predicted_11], \n",
    "                                    [\"Avoids FP:\", \"Avoids FN:\"]):\n",
    "    res.append([descr, \n",
    "                log_loss(actual, predicted)])\n",
    "    \n",
    "pd.DataFrame(res, columns=['type', 'log_loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Опишите, как бы вы предложили обобщить log-loss для мультиклассового случая**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ваш ответ: ?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}